{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behind-return",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,col\n",
    "from pyspark.sql.types import *\n",
    "#Connect to the cluster\n",
    "# New API\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.77:7077\") \\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .appName(\"pa_test1\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-furniture",
   "metadata": {},
   "source": [
    "## Load sentiment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valued-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlines = sc.textFile(\"hdfs://192.168.2.77:9000/user/ubuntu/negative-words.txt\")\n",
    "plines = sc.textFile(\"hdfs://192.168.2.77:9000/user/ubuntu/positive-words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-target",
   "metadata": {},
   "source": [
    "## Load comment data from hdfs and select columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legal-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"hdfs://192.168.2.77:9000/user/ubuntu/sample_data.json\")\n",
    "data_clean = df.select(\"subreddit\", \"body\", \"score\", \"controversiality\", \"created_utc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-figure",
   "metadata": {},
   "source": [
    "## Prepare negative and positive word data and broadcast it to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organizational-begin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.broadcast.Broadcast at 0x7f0561724160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_regexp(word_list):\n",
    "    re_string = \"[\\s\\W](\"\n",
    "    for word in word_list:\n",
    "        re_string += (re.escape(word) + \"|\")\n",
    "    re_string = re_string[0:-1] + \")[\\s\\W]\"\n",
    "    return re.compile(re_string, re.IGNORECASE)\n",
    "\n",
    "negative = compile_regexp(nlines.collect())\n",
    "sc.broadcast(negative)\n",
    "positive = compile_regexp(plines.collect())\n",
    "sc.broadcast(positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-possibility",
   "metadata": {},
   "source": [
    "## Define udf(s) to return the ratio of negativity and positivity for each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ancient-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_negative(comment, wc):\n",
    "    return len(negative.findall(comment))/wc\n",
    "\n",
    "def match_positive(comment, wc):\n",
    "    return len(positive.findall(comment))/wc\n",
    "\n",
    "def count_words(comment):\n",
    "    return len(comment.split())\n",
    "\n",
    "udf_match_negative = udf(match_negative, DoubleType())\n",
    "udf_match_positive = udf(match_positive, DoubleType())\n",
    "udf_count_words = udf(count_words, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "violent-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_clean.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-health",
   "metadata": {},
   "source": [
    "## Create columns negativity, positivity and wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "criminal-republican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+----------------+---------+--------------------+--------------------+-----------+\n",
      "|      subreddit|score|controversiality|wordcount|          negativity|          positivity|created_utc|\n",
      "+---------------+-----+----------------+---------+--------------------+--------------------+-----------+\n",
      "|      EchoArena|    1|               0|       55| 0.03636363636363636| 0.03636363636363636| 1506816000|\n",
      "|     The_Donald|    2|               0|        9|  0.2222222222222222|  0.1111111111111111| 1506816000|\n",
      "|       totalwar|    3|               0|      192|0.057291666666666664|             0.03125| 1506816000|\n",
      "|   tvcrossovers|    1|               0|       49|0.061224489795918366|0.061224489795918366| 1506816000|\n",
      "|     realmadrid|   10|               0|       13| 0.15384615384615385| 0.07692307692307693| 1506816000|\n",
      "|            CFB|    1|               0|       15| 0.06666666666666667| 0.13333333333333333| 1506816000|\n",
      "|     edc_raffle|    1|               0|      221| 0.01809954751131222| 0.01809954751131222| 1506816000|\n",
      "|       KCRoyals|    1|               0|       15| 0.06666666666666667| 0.13333333333333333| 1506816000|\n",
      "|    worldpowers|    1|               0|       52|0.019230769230769232|0.019230769230769232| 1506816001|\n",
      "|    hearthstone|    1|               0|       37| 0.02702702702702703| 0.05405405405405406| 1506816001|\n",
      "|        xboxone|  -19|               0|       21|0.047619047619047616| 0.09523809523809523| 1506816001|\n",
      "|    techtheatre|    2|               0|       33|0.030303030303030304| 0.09090909090909091| 1506816001|\n",
      "|        Ingress|    4|               0|      208|0.009615384615384616| 0.04807692307692308| 1506816001|\n",
      "|   TFABLinePorn|    2|               0|       27|0.037037037037037035|0.037037037037037035| 1506816001|\n",
      "|    Granblue_en|    2|               0|       92|0.021739130434782608| 0.05434782608695652| 1506816001|\n",
      "|  AskAnAmerican|    2|               0|      126|0.031746031746031744|0.023809523809523808| 1506816001|\n",
      "|          curvy|    1|               0|       71|0.056338028169014086|0.014084507042253521| 1506816001|\n",
      "|       totalwar|   22|               0|      231| 0.03896103896103896|0.030303030303030304| 1506816002|\n",
      "|    whowouldwin|    1|               0|      129|0.007751937984496124| 0.05426356589147287| 1506816002|\n",
      "|HomeImprovement|    6|               0|       67|0.014925373134328358|0.029850746268656716| 1506816002|\n",
      "+---------------+-----+----------------+---------+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_count = data_clean.withColumn('wordcount', udf_count_words('body'))\n",
    "negativity = w_count.withColumn('negativity', udf_match_negative('body', 'wordcount'))\n",
    "n_p_df = negativity.withColumn('positivity', udf_match_positive('body', 'wordcount'))\n",
    "filtered = n_p_df.select(\"subreddit\", \"score\", \"controversiality\", \"wordcount\", \"negativity\", \"positivity\", \"created_utc\").filter(\"positivity != 0 and negativity != 0\")\n",
    "filtered.show()\n",
    "#n_p_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-wagon",
   "metadata": {},
   "source": [
    "## Group by subreddit's average positivity and negativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continuing-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group By subreddit\n",
    "df1 = filtered.groupBy(\"created_utc\", \"subreddit\").avg(\"positivity\", \"negativity\")\n",
    "\n",
    "#find \"happiest\" subreddit of the day \n",
    "highest_average_positive = df1.agg({\"avg(positivity)\": \"max\"}).first()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-charles",
   "metadata": {},
   "source": [
    "## Define Happiness Ratio as the avg(pos/neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genuine-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Happiness Ration Col \n",
    "df2 = df1.withColumn(\"Happiness Ratio\", df1[\"avg(positivity)\"] / df1[\"avg(negativity)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "geological-edmonton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+--------------------+--------------------+-------------------+\n",
      "|created_utc|      subreddit|     avg(positivity)|     avg(negativity)|    Happiness Ratio|\n",
      "+-----------+---------------+--------------------+--------------------+-------------------+\n",
      "| 1506816209|            CFB| 0.09803921568627451|  0.0196078431372549|                5.0|\n",
      "| 1506816280|  todayilearned|0.041666666666666664| 0.08333333333333333|                0.5|\n",
      "| 1506816291|            DFO| 0.09090909090909091|0.045454545454545456|                2.0|\n",
      "| 1506816001|    techtheatre| 0.09090909090909091|0.030303030303030304|                3.0|\n",
      "| 1506816011|  linuxhardware| 0.03571428571428571| 0.08928571428571429|0.39999999999999997|\n",
      "| 1506816018|            WTF| 0.23076923076923078| 0.07692307692307693|                3.0|\n",
      "| 1506816041|           news| 0.05263157894736842| 0.05263157894736842|                1.0|\n",
      "| 1506816047|      starbucks|0.030303030303030304| 0.06060606060606061|                0.5|\n",
      "| 1506816049|  todayilearned| 0.04040404040404041| 0.06060606060606061| 0.6666666666666667|\n",
      "| 1506816061|         hockey| 0.08333333333333333| 0.08333333333333333|                1.0|\n",
      "| 1506816094|          vegan|0.043478260869565216|0.043478260869565216|                1.0|\n",
      "| 1506816115|      AskReddit| 0.03896103896103896|0.012987012987012988| 2.9999999999999996|\n",
      "| 1506816193|      AskReddit|0.045454545454545456|0.045454545454545456|                1.0|\n",
      "| 1506816215|   underpopular|0.008771929824561403| 0.02046783625730994|0.42857142857142855|\n",
      "| 1506816223|      AskReddit| 0.15458937198067632| 0.07729468599033816|                2.0|\n",
      "| 1506816225|DBZDokkanBattle| 0.06666666666666667| 0.02857142857142857| 2.3333333333333335|\n",
      "| 1506816298|     cringepics| 0.07142857142857142| 0.07142857142857142|                1.0|\n",
      "| 1506816015| PoliticalHumor|0.018518518518518517|0.018518518518518517|                1.0|\n",
      "| 1506816054|         Guitar|             0.09375|             0.03125|                3.0|\n",
      "| 1506816117|   buffalobills| 0.11538461538461539|0.038461538461538464|                3.0|\n",
      "+-----------+---------------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-world",
   "metadata": {},
   "source": [
    "## Convert unix time to \"MM-dd-yyyy HH:mm:ss\" Date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "preliminary-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert unix timestamp to \"MM-dd-yyyy HH:mm:ss\" Date format\n",
    "from pyspark.sql.functions import *\n",
    "df3 = df2.withColumn(\"created_utc\", (from_unixtime(col(\"created_utc\"),\"MM-dd-yyyy HH:mm:ss\").alias(\"created_utc\")))\n",
    "\n",
    "#find max hour \n",
    "#df3.agg({\"created_utc\": \"max\"}).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "featured-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(created_utc='10-01-2017 00:00:01', subreddit='techtheatre', avg(positivity)=0.09090909090909091, avg(negativity)=0.030303030303030304, Happiness Ratio=3.0),\n",
       " Row(created_utc='10-01-2017 00:00:11', subreddit='linuxhardware', avg(positivity)=0.03571428571428571, avg(negativity)=0.08928571428571429, Happiness Ratio=0.39999999999999997),\n",
       " Row(created_utc='10-01-2017 00:00:18', subreddit='WTF', avg(positivity)=0.23076923076923078, avg(negativity)=0.07692307692307693, Happiness Ratio=3.0),\n",
       " Row(created_utc='10-01-2017 00:00:41', subreddit='news', avg(positivity)=0.05263157894736842, avg(negativity)=0.05263157894736842, Happiness Ratio=1.0),\n",
       " Row(created_utc='10-01-2017 00:00:47', subreddit='starbucks', avg(positivity)=0.030303030303030304, avg(negativity)=0.06060606060606061, Happiness Ratio=0.5),\n",
       " Row(created_utc='10-01-2017 00:00:49', subreddit='todayilearned', avg(positivity)=0.04040404040404041, avg(negativity)=0.06060606060606061, Happiness Ratio=0.6666666666666667),\n",
       " Row(created_utc='10-01-2017 00:01:01', subreddit='hockey', avg(positivity)=0.08333333333333333, avg(negativity)=0.08333333333333333, Happiness Ratio=1.0),\n",
       " Row(created_utc='10-01-2017 00:01:34', subreddit='vegan', avg(positivity)=0.043478260869565216, avg(negativity)=0.043478260869565216, Happiness Ratio=1.0),\n",
       " Row(created_utc='10-01-2017 00:01:55', subreddit='AskReddit', avg(positivity)=0.03896103896103896, avg(negativity)=0.012987012987012988, Happiness Ratio=2.9999999999999996),\n",
       " Row(created_utc='10-01-2017 00:03:13', subreddit='AskReddit', avg(positivity)=0.045454545454545456, avg(negativity)=0.045454545454545456, Happiness Ratio=1.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dedicated-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "df4 = df3.withColumn(\"Hour\", hour(F.to_timestamp(\"created_utc\",\"MM-dd-yyyy HH:mm:ss\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "specific-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = filtered.groupBy(\"created_utc\", \"subreddit\").avg(\"positivity\", \"negativity\")\n",
    "df5 = df4.groupBy(\"Hour\").avg(\"Happiness Ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-tuner",
   "metadata": {},
   "source": [
    "## Happiness ration of reddit each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "south-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|Hour|avg(Happiness Ratio)|\n",
      "+----+--------------------+\n",
      "|   0|  1.4285350419065057|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-digest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
